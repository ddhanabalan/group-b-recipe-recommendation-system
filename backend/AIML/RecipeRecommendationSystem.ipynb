{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "813274fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdce6a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle(\"all_recipes.pkl\")\n",
    "df2=pd.read_pickle(\"all_users.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a68404",
   "metadata": {},
   "source": [
    "We Find one record which has a Null Attribute that can be filled manually with relevant data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f94ef05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[776, 'Veg/NonVeg'] = 'Non-Veg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b292a3a",
   "metadata": {},
   "source": [
    "Rest of the Null Attributes are beyond repair. so we drop them from the dataset for better model functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39e2fa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df.drop_duplicates(inplace=True)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6965b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dropna()\n",
    "df2.drop_duplicates(inplace=True)\n",
    "df2=df2.reset_index(drop=True)\n",
    "\n",
    "def processing(value):\n",
    "    return int(value)\n",
    "\n",
    "df2['rating']=df2['rating'].apply(processing)\n",
    "df2['recipe_id']=df2['recipe_id'].apply(processing)\n",
    "df2['user_id']=df2['user_id'].apply(processing)\n",
    "\n",
    "df2['date'] = pd.to_datetime(df2['date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d21f9b1",
   "metadata": {},
   "source": [
    "**CONVERTING THE FEATURES TO RELEVANT DATATYPE - REVIEWS, CALORIES, CATEGORY, INGREDIENTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d9be276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_k(value):\n",
    "    if 'k' in value:\n",
    "        value=str(value).split('k')\n",
    "        value=value[0]\n",
    "        value=float(value)*1000\n",
    "    return value\n",
    "\n",
    "df['reviews']=df['reviews'].apply(replace_k)\n",
    "\n",
    "def cat_2(value):\n",
    "    return eval(value)\n",
    "\n",
    "df['category']=df['category'].apply(cat_2)\n",
    "df['ingredients']=df['ingredients'].apply(cat_2)\n",
    "\n",
    "df['reviews']=df['reviews'].apply(processing)\n",
    "\n",
    "def calories(value):\n",
    "    if value.isdigit():\n",
    "        return int(value)\n",
    "    else:\n",
    "        return 1\n",
    "df['calories']=df['calories'].apply(calories)\n",
    "\n",
    "df = df.rename(columns={'ratings': 'avg_rating', 'reviews':'no_reviews', 'Season':'season','DaytimeOfCooking':'meal_type','Veg/NonVeg':'diet_type'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5701ba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['season'] = df['season'].apply(lambda x: x.split('/'))\n",
    "df['season'] = df['season'].apply(lambda x: ['Summer', 'Spring', 'Fall', 'Winter'] if x == ['Any'] else x)\n",
    "df['meal_type'] = df['meal_type'].apply(lambda x: x.split('/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "133947fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_ingredients(ingredients):\n",
    "    return len(ingredients)\n",
    "\n",
    "df['no_ingredients'] = df['ingredients'].apply(count_ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ec5c554",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'\\s*\\([^)]*\\)')\n",
    "records = df['diet_type']\n",
    "\n",
    "cleaned_records = [re.sub(pattern, '', record) for record in records]\n",
    "df['diet_type'] = cleaned_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b83558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    nopunct_text = ''.join([char for char in text if char.isalnum() or char.isspace()])\n",
    "    tokens = word_tokenize(nopunct_text)\n",
    "    return tokens[0]\n",
    "\n",
    "df['diet_type'] = df['diet_type'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21620b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a threshold for identifying significant outliers (e.g., 3 standard deviations above the mean)\n",
    "threshold = 3 * df['total_mins'].std()\n",
    "\n",
    "# Filter the dataset to include only records with cooking times exceeding the threshold\n",
    "outliers_df = df[df['total_mins'] > threshold]\n",
    "\n",
    "# Print the records with significant outlier cooking times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb670da",
   "metadata": {},
   "source": [
    "**OUTLIERS REMOVAL USING IQR METHOD**\n",
    "\n",
    "IQR is a robust statistical measure that represents the spread of the middle 50% of the data. It's calculated as the difference between the third quartile (Q3) and the first quartile (Q1).\n",
    "In recipe recommendation, outliers could be recipes with:\n",
    "\n",
    "    Extremely high or low cooking time.\n",
    "    Extremely high or low calories.\n",
    "    Unusually large or small numbers of ingredients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6287300e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25495/2791429900.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '933.375' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[(df[outlier]>upper_limit),outlier]=upper_limit\n",
      "/tmp/ipykernel_25495/2791429900.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '312.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[(df[outlier]>upper_limit),outlier]=upper_limit\n"
     ]
    }
   ],
   "source": [
    "def iqr_method(outlier):\n",
    "    #Removing Outliers by IQR Method\n",
    "    q1=df[outlier].quantile(0.25)\n",
    "    q3=df[outlier].quantile(0.75)\n",
    "    iqr=q3-q1\n",
    "    upper_limit = q3 + (1.5*iqr)\n",
    "    lower_limit = q1 - (1.5*iqr)\n",
    "    \n",
    "    df.loc[(df[outlier]>upper_limit),outlier]=upper_limit\n",
    "    df.loc[(df[outlier]<lower_limit),outlier]=lower_limit\n",
    "iqr_method('calories')\n",
    "iqr_method('no_ingredients')\n",
    "iqr_method('total_mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d18d9380",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded = df.explode('season')\n",
    "df_exploded2 = df.explode('meal_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39806eb0",
   "metadata": {},
   "source": [
    "**TOKENIZATION OF TITLE COLUMN**\n",
    "\n",
    "REMOVING OF STOP WORDS\n",
    "\n",
    "STOP WORDS - those words that occur very frequently in a statement that provide no particular meaning for the ML model training. it is simply existing for grammatical uses like connectors, verbs etc.\n",
    "\n",
    "eg. is, am, the, where, when, that, this etc.\n",
    "\n",
    "REMOVING SPECIAL CHARACTERS\n",
    "\n",
    "punctuations and other decorators were also removed for simplicity and accurate prediction of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36b783a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    nopunct_text = ''.join([char for char in text if char.isalnum() or char.isspace()])\n",
    "    tokens = word_tokenize(nopunct_text)\n",
    "    return tokens\n",
    "\n",
    "df['cleaned_titles'] = df['title'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ee1df47",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_feature(df, feature_name):\n",
    "    df[feature_name] = df[feature_name].apply(lambda row: lemmatize_list(row))\n",
    "    return df\n",
    "\n",
    "def lemmatize_list(list_of_strings):\n",
    "    lemmatized_list = [lemmatizer.lemmatize(word) for word in list_of_strings]\n",
    "    return lemmatized_list\n",
    "\n",
    "data = lemmatize_feature(df, 'cleaned_titles')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da2f858",
   "metadata": {},
   "source": [
    "Pre - Processing the CATEGORY feature\n",
    "\n",
    "removal of any special characters, conversion to lower cases and lemmatization of words for better computation\n",
    "after lemmatization, the stop words were removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e702043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_category_list(category_list):\n",
    "    lemmatized_list = []\n",
    "    for word in category_list:\n",
    "        lemmatized_category = []\n",
    "        lemmatized_category.append(lemmatizer.lemmatize(word.strip().lower()))\n",
    "        lemmatized_list.append(lemmatized_category)\n",
    "    return lemmatized_list\n",
    "\n",
    "df['category_lemmatized'] = df['category'].apply(lemmatize_category_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e26a7cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ingredients(ingredients):\n",
    "\n",
    "    ingredients=[ingredient.lower() for ingredient in ingredients]\n",
    "\n",
    "    pattern=r'[^\\w]'  # Matches any non-alphanumeric character\n",
    "    ingredients=[re.sub(pattern, ' ', ingredient) for ingredient in ingredients]\n",
    "\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    processed_ingredients=[[lemmatizer.lemmatize(word) for word in ingredients]]\n",
    "\n",
    "    return processed_ingredients\n",
    "\n",
    "ingre=df['ingredients'].apply(preprocess_ingredients)\n",
    "\n",
    "stop_words = stopwords.words('english') \n",
    "\n",
    "def filter_custom_stop_words(data):\n",
    "    new_stop_words =['taste','softened','teaspoon','teaspoons','tablespoons','cups','ounces','tablespoon',\n",
    "                     'cup','ounce','pinch','salt','ground','large','finely','chopped','grated','optional',\n",
    "                     'crushed','drained','divided','shredded','sliced','half','peeled','freshly','needed',\n",
    "                     'frying','prepared','cut','small','cube','water','warm','ml','l','g','kg','mg','dl',\n",
    "                     'gill','diced','pound','pint','quant','gallon','fl oz','°C','°F']\n",
    "    for i in new_stop_words:\n",
    "        stop_words.append(i)\n",
    "        \n",
    "    filtered_data = []\n",
    "    for recipe in data:\n",
    "        sublist2 = []\n",
    "        for sublist2_item in recipe:\n",
    "            for i in sublist2_item:\n",
    "                filtered_sublist3 = [word for word in i.split() if word not in stop_words and word.isalpha()]\n",
    "                sublist2.append(filtered_sublist3)\n",
    "        filtered_data.append(sublist2)\n",
    "    return filtered_data\n",
    "\n",
    "#function call for filtering\n",
    "filtered_data = filter_custom_stop_words(ingre)\n",
    "\n",
    "df['ingredients_filtered']=filtered_data\n",
    "\n",
    "def join_lists(data):\n",
    "\n",
    "    joined_list = []\n",
    "    for sublist in data:\n",
    "        joined_list.append([' '.join(x) for x in sublist])  # Join elements with space\n",
    "    return joined_list\n",
    "\n",
    "# Join elements in each sublist\n",
    "df['ingredients_filtered'] = join_lists(df['ingredients_filtered'])\n",
    "df['category_lemmatized'] = join_lists(df['category_lemmatized'])\n",
    "df['category_lemmatized']=df['category_lemmatized'].apply(lambda x: ', '.join(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18782932",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['title','category','ingredients'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20141329",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df['ingredients_filtered']:\n",
    "    for j in i:\n",
    "        if len(j)<1:\n",
    "            i.remove(j)\n",
    "            \n",
    "def to_string(value):\n",
    "    comb_str=' '.join(value)\n",
    "    return comb_str\n",
    "\n",
    "df['ingredients_filtered']=df['ingredients_filtered'].apply(to_string)\n",
    "ingredients_filtered=df[['recipe_id','ingredients_filtered']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7830c33b",
   "metadata": {},
   "source": [
    "**RECOMMENDATION BASED ON INGREDIENT SIMILARITY**\n",
    "\n",
    "I DID THIS BY TAKING THE VECTOR FORMAT OF THE INGREDIENTS, CATEGORY AND TITLE COLUMN OF EACH RECIPE AND THEN FURTHER PLOTTING THE SIMILARITY BETWEEN EACH RECIPE USING COSINE SIMILARITY.\n",
    "THIS IS DONE BY USING THE K-NEAREST NEIGHBOURS ALGORITHM. HERE K IS CHOSEN TO BE 10.\n",
    "\n",
    "\n",
    "THIS MODEL SUGGESTS SIMILAR RECIPES WHEN ONE RECIPE IS VIEWED. THIS COULD GIVE OPTIONS FOR THE USER TO PICK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a8ea1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer()\n",
    "\n",
    "df['combined_text'] = df['cleaned_titles'].apply(' '.join) + ' ' + df['ingredients_filtered'] + ' ' + df['category_lemmatized']\n",
    "\n",
    "\n",
    "recipe_text_features = vectorizer.fit_transform(df['combined_text'])\n",
    "\n",
    "similarity=cosine_similarity(recipe_text_features, recipe_text_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c86342d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations list: [263516, 263516, 222337, 263749, 221068, 246868, 221954, 232799, 254553]\n"
     ]
    }
   ],
   "source": [
    "knn = NearestNeighbors(n_neighbors=10, algorithm='auto', metric='cosine')\n",
    "knn.fit(recipe_text_features)\n",
    "\n",
    "def recommend_recipe(recipe_id):\n",
    "    \n",
    "    if recipe_id not in df['recipe_id'].values:\n",
    "        print(\"Recipe ID not found.\")\n",
    "        return []\n",
    "    \n",
    "    recipe_index = df.index[df['recipe_id'] == recipe_id].tolist()[0]\n",
    "    \n",
    "    #fetching nearest neighbors for the recipe at the found index\n",
    "    distances, indices = knn.kneighbors(recipe_text_features[recipe_index].reshape(1, -1), n_neighbors=10)\n",
    "    recommendations = []\n",
    "\n",
    "    for i in range(1, len(distances.flatten())):\n",
    "        recommended_recipe_id = df['recipe_id'][indices.flatten()[i]]\n",
    "        recommendations.append(recommended_recipe_id)\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "#example\n",
    "recommendations_list = recommend_recipe(220596)\n",
    "print(\"Recommendations list:\", recommendations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fb53c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[229442, 223041, 219636, 220596, 255011, 230318, 263516, 263516, 245442]\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(recommend_recipe, open('KNN_model.pkl','wb'))\n",
    "'''loaded_recommend_recipes = pickle.load(open(\"KNN_model.pkl\", \"rb\"))\n",
    "print(loaded_recommend_recipes(222337))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2190b2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ingredients_filtered'] = df['ingredients_filtered'].apply(lambda x: ''.join(x))\n",
    "df['cleaned_titles'] = df['cleaned_titles'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff394603",
   "metadata": {},
   "source": [
    "**MATRIX FACTORIZATION USING USER RATING AND COMBINATION OF INGREDIENTS,TITLE AND CATEGORY OF FOOD**\n",
    "\n",
    "MATRIX FACTORIZATION IS COMMONLY USED FOR DETECTING A PATTERN BETWEEN DIFFERENT USERS AND THEIR INTEREST. SINCE WE HAVE DATASET OF USER RATING FOR DIFFERENT RECIPES, WE COULD PLOT USER VS. RECIPE MATRIX. THIS COULD SUGGEST RECIPES FOR A USER THAT WAS ACCEPTED BY A SIMILAR USER.\n",
    "\n",
    "FOR THIS MODEL, THE INPUT IS USER_ID AND OUTPUT IS A SERIES OF RECIPE_ID'S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ee781f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_recipe_df=df2.merge(df,on='recipe_id')\n",
    "\n",
    "#user-recipe matrix\n",
    "\n",
    "user_recipe_df = user_recipe_df[user_recipe_df['rating'] >= 3]\n",
    "rating_matrix=user_recipe_df.pivot_table(values='rating',index='user_id',columns='recipe_id').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65263c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([219166, 234534, 220127, 219077, 233170, 219967, 239047, 221887, 222187,\n",
      "       234803],\n",
      "      dtype='int64', name='recipe_id')\n"
     ]
    }
   ],
   "source": [
    "num_factors=10\n",
    "\n",
    "#perform NMF Non-Negative Matrix Factorization\n",
    "nmf = NMF(n_components=num_factors, random_state=42)\n",
    "user_factors=nmf.fit_transform(rating_matrix)\n",
    "recipe_factors=nmf.components_\n",
    "\n",
    "user_id_to_index = {user_id: idx for idx, user_id in enumerate(rating_matrix.index)}\n",
    "\n",
    "# Function to recommend recipes based on user ID\n",
    "def recommend_recipes(user_id, top_n=10):\n",
    "    if user_id not in user_id_to_index:\n",
    "        print(f\"User ID {user_id} not found.\")\n",
    "        return []\n",
    "    \n",
    "    user_index = user_id_to_index[user_id]\n",
    "    user_factor = user_factors[user_index]\n",
    "    predicted_ratings = user_factor.dot(recipe_factors)\n",
    "    top_recipe_indices = predicted_ratings.argsort()[-top_n:][::-1]  # Get top n indices, sorted in descending order\n",
    "    \n",
    "    # Map indices back to recipe IDs\n",
    "    top_recipe_ids = rating_matrix.columns[top_recipe_indices]\n",
    "    return top_recipe_ids\n",
    "\n",
    "#recommendations for user with ID \n",
    "recommended_recipes_CF=recommend_recipes(16)\n",
    "\n",
    "print(recommended_recipes_CF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "afb17c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([219166, 234534, 220127, 219077, 233170, 219967, 239047, 221887, 222187,\n",
       "       234803],\n",
       "      dtype='int64', name='recipe_id')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle.dump(recommend_recipes, open('CF_model.pkl','wb'))\n",
    "'''CF_recommend_recipes = pickle.load(open(\"CF_model.pkl\", \"rb\"))\n",
    "CF_recommend_recipes(16)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
